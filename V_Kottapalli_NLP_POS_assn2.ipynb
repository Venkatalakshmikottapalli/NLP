{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlbFw3jNWwNhzR6bdcqHTH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venkatalakshmikottapalli/NLP/blob/main/V_Kottapalli_NLP_POS_assn2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-based and Statistical Approaches for Part-of-Speech Tagging"
      ],
      "metadata": {
        "id": "ZfbOS1ScKo0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction:\n",
        "\n",
        "Part-of-Speech (POS) tagging assigns grammatical tags to words in a sentence, identifying their syntactic categories such as nouns, verbs, adjectives, etc. It's essential for various NLP tasks like parsing and machine translation. There are two main approaches to POS tagging: rule-based methods, which use predefined rules to tag words, and statistical methods, which use machine learning models like Hidden Markov Models (HMMs) or Maximum Entropy Markov Models (MEMMs).\n",
        "\n",
        "In this assignment, we will:\n",
        "\n",
        "Implement a rule-based POS tagger by writing rules to assign tags based on word context and evaluate its accuracy.\n",
        "Develop a statistical POS tagger by training a machine learning model on a labeled corpus and assess its performance.\n"
      ],
      "metadata": {
        "id": "Y6oZXM9BXdYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwmJP8kAKSLf",
        "outputId": "e53d68e7-7a18-4ef8-945e-0bfaef9e18c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker') #The maxent_ne_chunker contains two pre-trained English named entity chunkers trained on an ACE corpus (perhaps ACE ACE 2004 Multilingual Training Corpus?)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        " We have downloaded the libraries and set up the NLTK environment needed for various natural language processing tasks:\n",
        "- Tokenization: Punkt tokenizer (punkt).\n",
        "- Part-of-Speech Tagging: Averaged perceptron tagger -\n",
        "(averaged_perceptron_tagger).\n",
        "- Training and evaluating models:(treebank)\n",
        "- Named Entity Recognition: Maximum entropy named entity chunker (maxent_ne_chunker)."
      ],
      "metadata": {
        "id": "4p-fzJbWgAHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger #important for POS tagging"
      ],
      "metadata": {
        "id": "xRhlLyftK9np"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        "- We have imported the libraries from the nltk\n",
        "- POS Tagging (pos_tag): Used to assign POS tags to words in sentences.\n",
        "- Named Entity Recognition (ne_chunk): Used to recognize and categorize named entities in text.\n",
        "- Tokenization (word_tokenize): Used to split text into individual words or tokens.\n",
        "- Penn Treebank Corpus (treebank): Provides access to a widely-used corpus of English text with detailed annotations.\n",
        "- Taggers (DefaultTagger, UnigramTagger, BigramTagger): Provide different methods for automatically assigning POS tags to words based on statistical models."
      ],
      "metadata": {
        "id": "HocegCt6mOQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "\n",
        "# Rule-based POS Tagger\n",
        "def rule_based_pos_tagger(sentence):\n",
        "    # Define your rules here\n",
        "    rules = [\n",
        "          (re.compile(r'\\bThe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bcat\\b'), 'NN'),\n",
        "          (re.compile(r'\\bis\\b'), 'VB'),\n",
        "          (re.compile(r'\\bsitting\\b'), 'VB'),\n",
        "          (re.compile(r'\\bon\\b'), 'IN'),\n",
        "          (re.compile(r'\\bthe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bmat\\b'), 'NN'),\n",
        "      ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        for pattern, tag in rules:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                break\n",
        "        else:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n"
      ],
      "metadata": {
        "id": "PnLQ9sIXLFEe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comment\n",
        "- First we have defined a function rule_based_pos_tagger\n",
        "- the rules have\n",
        "- (re.compile(r'\\bThe\\b'), 'DT') - Matches the word The and gives the tag 'DT' (determiner)\n",
        "- (re.compile(r'\\bcat\\b'), 'NN')- Matches the word cat and gives the tag 'NN' (Noun)\n",
        "- (re.compile(r'\\bis\\b'), 'VB') - Matches the word is and gives the tag 'VB' (Verb)\n",
        "- (re.compile(r'\\bsitting\\b'), 'VB') - Matches the word sitting and gives the tag 'VB' (Verb)\n",
        "- (re.compile(r'\\bon\\b'), 'IN') - Matches the word on and gives the tag 'IN' (prepositions)\n",
        "- (re.compile(r'\\bthe\\b'), 'DT') - Matches the word the and gives the tag 'DT' (determiner)\n",
        "- (re.compile(r'\\bmat\\b'), 'NN') - Matches the word mat and gives the tag 'NN' (Noun)\n",
        "- after that we have created an empty list to store the tokens with tags\n",
        "- tokenized the words with word_tokenize\n",
        "- the loop checks each token to match with the pattern. if it matches it assigns the tag or it assigns unknown\n",
        "- finally returned the list"
      ],
      "metadata": {
        "id": "xZ0rOJuYp0Uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UW7Ud-plpNQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical POS Tagger\n",
        "def statistical_pos_tagger(sentence):\n",
        "    # Train your model on a labeled corpus (e.g., treebank)\n",
        "    train_data = treebank.tagged_sents()[:3000]\n",
        "    # Train your statistical model here\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_size = int(len(train_data) * 0.8)\n",
        "    train_set = train_data[:train_size]\n",
        "    test_set = train_data[train_size:]\n",
        "\n",
        "    # Create taggers\n",
        "    default_tagger = DefaultTagger('NN')  # Default tagger assigns 'NN' to all words\n",
        "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)  # Unigram tagger using training set\n",
        "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)  # Bigram tagger using training set and fallback to unigram tagger\n",
        "\n",
        "    # Evaluate on test set\n",
        "    accuracy = bigram_tagger.accuracy(test_set)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "    # Apply the trained model to tag the sentence\n",
        "    tagged_sentence  = bigram_tagger.tag(word_tokenize(sentence))\n",
        "    #tagged_sentence = nltk.pos_tag(words)\n",
        "    #tagged_sentence.append(tagged_sentence)\n",
        "    return tagged_sentence"
      ],
      "metadata": {
        "id": "Ew3wjTzbLPBm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        "- The statistical_pos_tagger function demonstrates a statistical approach to POS tagging using NLTK's taggers (DefaultTagger, UnigramTagger, BigramTagger).\n",
        "- Frist we have retrieved the 3000 tagged sentences from the treebank corpus\n",
        "- Then, we splitted the data into training and testing data\n",
        "- first all words assigned with DefaultTagger 'NN' and UnigramTagger assigns unigram tagger using training set\n",
        "- later, BigramTagger assigns bigram tagger using training set\n",
        "- Calculated the accuracy\n",
        "- Applied the statisticsl approach to the sentence and returned it."
      ],
      "metadata": {
        "id": "EFUM66RUtUzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "# Rule-based POS Tagging\n",
        "rule_based_tags = rule_based_pos_tagger(sample_sentence)\n",
        "print(\"Rule-based POS Tags:\")\n",
        "print(rule_based_tags)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "statistical_tags = statistical_pos_tagger(sample_sentence)\n",
        "print(\"Statistical POS Tags:\")\n",
        "print(statistical_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZH7oeD4Ljq5",
        "outputId": "84f923ef-884b-43d3-f0a0-4347f5a512eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VB'), ('sitting', 'VB'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', 'UNKNOWN')]\n",
            "Accuracy: 0.8748033560566335\n",
            "Statistical POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        "- Here we applied both rule based and statistical tagging to the sample sentence and printed the results."
      ],
      "metadata": {
        "id": "OdcAxbGWxVuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, NLTK has a built in function call ```pos_tags`` See example below"
      ],
      "metadata": {
        "id": "OivMqzsTyS4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "tagged_sentence = nltk.pos_tag(word_tokenize(sample_sentence))\n",
        "print(tagged_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJcmK6HYyZTz",
        "outputId": "1d4cdfc5-3f07-44fd-a957-3ccb63698cc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sent = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "# Function with updated rule based POS tagger\n",
        "def updated_pos_tag_regex(sentence):\n",
        "    patterns = [\n",
        "        (re.compile(r'\\b(The|the|an|An|a|A)\\b'), 'DT'),  # Determiners\n",
        "        (re.compile(r'\\b(quick|brown|lazy)\\b'), 'JJ'),  # Adjectives\n",
        "        (re.compile(r'\\b(fox|dog)\\b'), 'NN'),  # Nouns\n",
        "        (re.compile(r\"\\bjumps\\b|\\'s\\b\"), 'VBZ'),  # Verbs\n",
        "        (re.compile(r'\\b(while|over|and)\\b'), 'IN'),  # Conjunctions\n",
        "        (re.compile(r'\\b(it|he|she)\\b'), 'PRP'),  # Pronouns\n",
        "        (re.compile(r'\\b\\w+ing\\b'), 'VBG'),  # Gerunds ending in 'ing'\n",
        "        (re.compile(r'\\b\\w+ly\\b'), 'RB'),  # Adverbs ending in 'ly'\n",
        "        (re.compile(r'\\b\\w+ed\\b'), 'VBD'),  # Verbs ending in 'ed'\n",
        "        (re.compile(r'\\b\\w+s\\b|\\b\\w+es\\b'), 'NNS'),  # Plural nouns ending in 's' or 'es'\n",
        "        (re.compile(r'\\.'), '.'),  # Full stop\n",
        "        (re.compile(r'\\,'), ','),  # Comma\n",
        "    ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        tagged = False\n",
        "        for pattern, tag in patterns:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                tagged = True\n",
        "                break\n",
        "        if not tagged:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "1O5o1BP9L-9u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comment:\n",
        "- Here the rule_based_pos_tagger updated as updated_pos_tagger.\n",
        "- (re.compile(r'\\b\\w+ed\\b'), 'VBD') -  Matches the word with ed and gives the tag 'VBD' (Verb in Past).\n",
        "- (re.compile(r'\\b\\w+ly\\b'), 'RB') - Matches the word with ly and gives the tag 'RB' (Adverb).\n",
        "- (re.compile(r'\\b\\w+ing\\b'), 'VBG') - Matches the word with ing and gives the tag 'VBG' (Gerund).\n",
        "- (re.compile(r'\\b(The|the|an|An|a|A)\\b'), 'DT') - Matches the word artucle and gives the tag 'DET' (article).\n",
        "- (re.compile(r'\\b(quick|brown|lazy)\\b'), 'JJ') - Matches the word quick or brown or lazy and gives the tag 'JJ' (Adjective).\n",
        "- (re.compile(r'\\b(fox|dog)\\b'), 'NN') - Matches the word fox or dog and gives the tag 'NN' (Noun).\n",
        "- (re.compile(r\"\\bjumps\\b|\\'s\\b\"), 'VBZ') - Matches the jumps or 's and gives the tag 'VBZ' (verb).\n",
        "- (re.compile(r'\\b(while|over|and)\\b'), 'IN')- Matches the word while or over or and and gives the tag 'In' (Conjunctions or Prepositions).\n",
        "- (re.compile(r'\\b(it|he|she)\\b'), 'PRP') - Matches the word with it or he or she and gives the tag 'PRP' (Pronoun).\n",
        "- (re.compile(r'\\b\\w+s\\b|\\b\\w+es\\b'), 'NNS') Matches the word with es or s and gives the tag 'NNS' (Noun with plurals).\n",
        "- (re.compile(r'\\.'), '.') Matches the '.' and gives the tag '.' (full stop ).\n",
        "- (re.compile(r'\\,'), ',') Matches the ',' and gives the tag ',' (comma).\n",
        "\n",
        "- after that we have created an empty list to store the tokens with tags\n",
        "- tokenized the words with word_tokenize\n",
        "- the loop checks each token to match with the pattern. if it matches it assigns the tag or it assigns unknown\n",
        "- finally returned the list"
      ],
      "metadata": {
        "id": "GBdCcVbtz3nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule based POS Tagger and statistical POS Tagger"
      ],
      "metadata": {
        "id": "ABW9BmRozUKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the improved Rule-based POS Tagger\n",
        "sent = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "\n",
        "# Rule-based POS Tagging\n",
        "rule_based_tags_updated = updated_pos_tag_regex(sent)\n",
        "print(\"Rule-based POS Tags (Updated):\")\n",
        "print(rule_based_tags_updated)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "statistical_tags = statistical_pos_tagger(sent)\n",
        "print(\"Statistical POS Tags:\")\n",
        "print(statistical_tags)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "nltk_tagged_sent = nltk.pos_tag(word_tokenize(sent))\n",
        "print(\"NLTK Statistical POS Tags:\")\n",
        "print(nltk_tagged_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4-iOnu6Ktq",
        "outputId": "5007c5dc-275a-483a-e297-e1b941d675e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags (Updated):\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', '.')]\n",
            "Accuracy: 0.8748033560566335\n",
            "Statistical POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'NN'), ('heavily', 'RB'), ('.', '.')]\n",
            "NLTK Statistical POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comment:\n",
        "- Here we applied  rule based, nltk pos tagging and statistical tagging to the sample sentence and printed the results"
      ],
      "metadata": {
        "id": "-qFYycOUW1Bk"
      }
    }
  ]
}